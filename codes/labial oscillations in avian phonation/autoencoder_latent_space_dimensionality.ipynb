{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2Eaq5WXSpni"
   },
   "source": [
    "**Code for Paper \"The reconstruction of flows from spatiotemporal data by autoencoders\"**\n",
    "\n",
    "Facundo Fainstein (1,2), Josefina Catoni (1), Coen Elemans (3) and Gabriel B. Mindlin (1,2,4)* \n",
    "\n",
    "(1) Universidad de Buenos Aires, Facultad de Ciencias Exactas y Naturales, Departamento de Física, Ciudad Universitaria, 1428 Buenos Aires, Argentina.\n",
    "\n",
    "(2) CONICET - Universidad de Buenos Aires, Instituto de Física Interdisciplinaria y Aplicada (INFINA), Ciudad Universitaria, 1428 Buenos Aires, Argentina.\n",
    "\n",
    "(3) Department of Biology, University of Southern Denmark, 5230 Odense M, Denmark.\n",
    "\n",
    "(4) Universidad Rey Juan Carlos, Departamento de Matemática Aplicada, Madrid, Spain. \n",
    "\n",
    "*Gabriel B. Mindlin (corresponding author)\n",
    "Email: gabo@df.uba.ar\n",
    "\n",
    "\n",
    "**Train autoencoder with different latent space dimensions** \n",
    "\n",
    "Do 100 fittings of an autoencoder. The architecture is: 9900-64-32-16-NUM_MODOS-16-32-64-9900. \n",
    "\n",
    "Save the results in .txt files. \n",
    "\n",
    "To fit networks with different latent space dimensions change the number of units in the middle layer ('NUM_MODOS')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28015,
     "status": "ok",
     "timestamp": 1632840788151,
     "user": {
      "displayName": "Josefina Catoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01167242815319300630"
     },
     "user_tz": 180
    },
    "id": "FnYKLMg4e6cz",
    "outputId": "71a2c676-abcc-4c11-a7ba-7e7b3fc26d64"
   },
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from numpy import loadtxt\n",
    "from skimage import io\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras import backend as K\n",
    "\n",
    "#Uncomment the following lines if run in google colab \n",
    "\n",
    "# from google.colab import drive\n",
    "#Mount drive to load images\n",
    "#drive.mount('/content/gdrive', force_remount=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "#Movie folder\n",
    "root_dir = f'/home/.../' \n",
    "#Save file names in list\n",
    "lista_files=[]\n",
    "lista_files=glob.glob(root_dir+'*.jpg')\n",
    "lista_files.sort()\n",
    "\n",
    "#Load data\n",
    "data = []\n",
    "for file in lista_files:\n",
    "  img = io.imread(file, as_gray=True)\n",
    "  data.append(img)  \n",
    "data = np.array(data)\n",
    "print(data.shape)\n",
    "\n",
    "#Define the pixels of each images to analyze\n",
    "x_der = data[:,120:230,180:270].astype('float32')\n",
    "\n",
    "#Compute the temporal mean value of each pixel\n",
    "xmean_der=np.mean(x_der,axis=0) \n",
    "\n",
    "#Substract the mean \n",
    "x_der -= xmean_der\n",
    "print(type(x_der))\n",
    "print(x_der.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a function that fits the network and saves the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9AH9JbwE0Dy"
   },
   "outputs": [],
   "source": [
    "#Customized callback to save the encoding and the test MSE at each epoch of the training procedure\n",
    "\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, model, x_test, model_path):\n",
    "        self.model = model\n",
    "        self.x_test = x_test\n",
    "        self.model_path = model_path\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        get_latent_layer_output = K.function([self.model.layers[0].input],\n",
    "                                             [self.model.layers[4].output])\n",
    "        layer_output_test = get_latent_layer_output ([self.x_test])[:][0]\n",
    "        y_pred = self.model.predict(self.x_test)\n",
    "        rec_error_test=np.sum((self.x_test-y_pred)**2,axis=1)\n",
    "        filename_1 = '/ls_test_epoch_'+str(epoch)+\".txt\"\n",
    "        filename_2 = '/mse_test_epoch_'+str(epoch)+\".txt\"\n",
    "        np.savetxt(model_path+filename_1, layer_output_test)\n",
    "        np.savetxt(model_path+filename_2, rec_error_test)\n",
    "\n",
    "#Function that creates and trains the network, and saves the results\n",
    "\n",
    "def train_save(X, model_path,NUM_MODOS):\n",
    "    # X = data\n",
    "    # X = [time, rows*columns pixels]\n",
    "    # model_path = path to folder in which results will be saved\n",
    "    \n",
    "    #Separate train and test data sets\n",
    "    X_train, X_test = X[0:300], X[300:]\n",
    "  \n",
    "\n",
    "    #Define the network\n",
    "    numero_pixeles = X.shape[1]\n",
    "    input_img = keras.Input(shape=(numero_pixeles,))\n",
    "    encoded = layers.Dense(64, activation='relu')(input_img)\n",
    "    encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "    encoded = layers.Dense(16, activation='relu')(encoded)\n",
    "    encoded = layers.Dense(NUM_MODOS, activation='linear')(encoded)\n",
    "    decoded = layers.Dense(16, activation='relu')(encoded)\n",
    "    decoded = layers.Dense(32, activation='relu')(decoded)\n",
    "    decoded = layers.Dense(64, activation='relu')(decoded)\n",
    "    decoded = layers.Dense(numero_pixeles, activation='linear')(decoded)\n",
    "\n",
    "    #Create the autoencoder\n",
    "    autoencoder = keras.Model(input_img, decoded)\n",
    "  \n",
    "    #Compile the model\n",
    "    autoencoder.compile(loss='mse', metrics=['mean_absolute_error'], optimizer='adam')\n",
    "\n",
    "    #Train the model and save metrics in history\n",
    "    history = autoencoder.fit(X_train, X_train,\n",
    "            batch_size=16, epochs=200,\n",
    "            validation_data=(X_test, X_test),\n",
    "            verbose=0, callbacks=[CustomCallback(autoencoder,X_test, model_path)]);\n",
    "\n",
    "    #Get results from trained net\n",
    "    train_mse = np.array(history.history['loss'])\n",
    "    val_mse = np.array(history.history['val_loss'])\n",
    "    optimal_epoch=np.argmin(train_mse)\n",
    "    \n",
    "    #Delete results of every epoch except the one with minimum mse for the train set\n",
    "    indexes=np.setdiff1d(np.arange(200),[optimal_epoch])\n",
    "    for index in set(indexes):\n",
    "        os.remove(model_path+'/ls_test_epoch_'+str(index)+\".txt\")\n",
    "        os.remove(model_path+'/mse_test_epoch_'+str(index)+\".txt\")\n",
    "\n",
    "    #Save \n",
    "    np.savetxt(model_path+'/train_mse.txt', train_mse)\n",
    "    np.savetxt(model_path+'/val_mse.txt', val_mse)\n",
    "\n",
    "    return train_mse,val_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVfV1k0mIhon"
   },
   "source": [
    "**Fit N times**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6693452,
     "status": "ok",
     "timestamp": 1632847663716,
     "user": {
      "displayName": "Josefina Catoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01167242815319300630"
     },
     "user_tz": 180
    },
    "id": "lFKIldGuIg55",
    "outputId": "47414baf-c0a2-451e-c9be-40c1c184b70b"
   },
   "outputs": [],
   "source": [
    "#Define data \n",
    "X = x_der.reshape(x_der.shape[0], x_der.shape[1]*x_der.shape[2])\n",
    "d_frames_test = np.sqrt(np.sum(np.diff(X[300:],axis=0)**2,axis=1))\n",
    "\n",
    "#Define number of units in the middle layer\n",
    "NUM_MODOS=4\n",
    "\n",
    "#Number of trainings\n",
    "N=1\n",
    "path = f'/home/.../'\n",
    "\n",
    "for k in range(N):\n",
    "    print('iteracion ' + str(k) + ' de '+str(N))\n",
    "    #Create name to save training results\n",
    "    directory= 'dim_LS_'+str(NUM_MODOS)+'_it{}'.format(k)\n",
    "    model_path = os.path.join(path, directory)\n",
    "    Path(model_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #Train and save\n",
    "    (train_mse,val_mse)= train_save(X,model_path=model_path,NUM_MODOS=NUM_MODOS)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2021_09_25_entrenamientos_m23_dimLS.ipynb",
   "provenance": [
    {
     "file_id": "1YgTJF2HyeY-E0_KzZHuerP_DNsau8uwr",
     "timestamp": 1630448146369
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
