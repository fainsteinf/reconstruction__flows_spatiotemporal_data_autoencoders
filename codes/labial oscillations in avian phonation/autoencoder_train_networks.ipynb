{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2Eaq5WXSpni"
   },
   "source": [
    "**Code for Paper \"The reconstruction of flows from spatiotemporal data by autoencoders\"**\n",
    "\n",
    "Facundo Fainstein (1,2), Josefina Catoni (1), Coen Elemans (3) and Gabriel B. Mindlin (1,2,4)* \n",
    "\n",
    "(1) Universidad de Buenos Aires, Facultad de Ciencias Exactas y Naturales, Departamento de Física, Ciudad Universitaria, 1428 Buenos Aires, Argentina.\n",
    "\n",
    "(2) CONICET - Universidad de Buenos Aires, Instituto de Física Interdisciplinaria y Aplicada (INFINA), Ciudad Universitaria, 1428 Buenos Aires, Argentina.\n",
    "\n",
    "(3) Department of Biology, University of Southern Denmark, 5230 Odense M, Denmark.\n",
    "\n",
    "(4) Universidad Rey Juan Carlos, Departamento de Matemática Aplicada, Madrid, Spain. \n",
    "\n",
    "*Gabriel B. Mindlin (corresponding author)\n",
    "Email: gabo@df.uba.ar\n",
    "\n",
    "\n",
    "**Train autoencoder** \n",
    "\n",
    "Fit 100 autoencoders. The architecture is: 9900-64-32-16-2-16-32-64-9900. Save the results in .txt files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "FnYKLMg4e6cz"
   },
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from numpy import loadtxt\n",
    "from skimage import io\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras import backend as K\n",
    "\n",
    "#Uncomment the following lines if run in google colab \n",
    "\n",
    "# from google.colab import drive\n",
    "#Mount drive to load images\n",
    "#drive.mount('/content/gdrive', force_remount=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfT4bX-8-Aom"
   },
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "zLEj11e8m_O6"
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "#Movie folder\n",
    "root_dir = f'/media/.../' \n",
    "#Save file names in list\n",
    "lista_files=[]\n",
    "lista_files=glob.glob(root_dir+'*.jpg')\n",
    "lista_files.sort()\n",
    "\n",
    "#Load data\n",
    "data = []\n",
    "for file in lista_files:\n",
    "  img = io.imread(file, as_gray=True)\n",
    "  data.append(img)  \n",
    "data = np.array(data)\n",
    "print(data.shape)\n",
    "\n",
    "#Define the pixels of each images to analyze\n",
    "x_der = data[:,120:230,180:270].astype('float32')\n",
    "\n",
    "#Compute the temporal mean value of each pixel\n",
    "xmean_der=np.mean(x_der,axis=0) \n",
    "\n",
    "#Substract the mean \n",
    "x_der -= xmean_der\n",
    "print(type(x_der))\n",
    "print(x_der.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLQ8Q9Fk-Aon"
   },
   "source": [
    "**Define a function that fits the network and saves the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9AH9JbwE0Dy"
   },
   "outputs": [],
   "source": [
    "#Function that creates and trains the network, and saves the results\n",
    "def train_save(X, model_path):\n",
    "    # X = data\n",
    "    # X = [time, rows*columns pixels]\n",
    "    # model_path = path to folder in which results will be saved\n",
    "    \n",
    "    #Separate train and test data sets\n",
    "    X_train, X_test = X[0:300], X[300:]\n",
    "    \n",
    "    #Define the network\n",
    "    numero_pixeles = X.shape[1]\n",
    "    input_img = keras.Input(shape=(numero_pixeles,))\n",
    "    encoded = layers.Dense(64, activation='relu')(input_img)\n",
    "    encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "    encoded = layers.Dense(16, activation='relu')(encoded)\n",
    "    encoded = layers.Dense(2, activation='linear')(encoded)\n",
    "    decoded = layers.Dense(16, activation='relu')(encoded)\n",
    "    decoded = layers.Dense(32, activation='relu')(decoded)\n",
    "    decoded = layers.Dense(64, activation='relu')(decoded)\n",
    "    decoded = layers.Dense(numero_pixeles, activation='linear')(decoded)#Create the autoencoder\n",
    "    autoencoder = keras.Model(input_img, decoded)\n",
    "\n",
    "    #Compile the model\n",
    "    autoencoder.compile(loss='mse', metrics=['mean_absolute_error'], optimizer='adam')\n",
    "\n",
    "    # training the model and saving metrics in history\n",
    "    history = autoencoder.fit(X_train, X_train,\n",
    "                batch_size=16, epochs=200,\n",
    "                validation_data=(X_test, X_test),\n",
    "                verbose=0);\n",
    "\n",
    "    #Get results from trained net\n",
    "    train_mse = np.array(history.history['loss'])  #MSE for the train data set\n",
    "    val_mse = np.array(history.history['val_loss']) #MSE for the test data set\n",
    "    get_latent_layer_output = K.function([autoencoder.layers[0].input],[autoencoder.layers[4].output])\n",
    "    layer_output_train = get_latent_layer_output ([X_train])[:][0]  #Latent space projection for the training set\n",
    "    prediction_test = autoencoder.predict(X_test)  #Output of the test set\n",
    "    layer_output_test = get_latent_layer_output ([X_test])[:][0] #Latent space projection for the test set\n",
    "\n",
    "    #Save results \n",
    "    np.savetxt(model_path+'/train_mse.txt', train_mse)\n",
    "    np.savetxt(model_path+'/val_mse.txt', val_mse)\n",
    "    np.savetxt(model_path+'/layer_output_train.txt', layer_output_train)\n",
    "    np.savetxt(model_path+'/layer_output_test.txt', layer_output_test)\n",
    "#     np.savetxt(model_path+'/recostruction_test.txt', prediction_test) #Uncomment if needed\n",
    "\n",
    "    return train_mse,val_mse,layer_output_train,layer_output_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVfV1k0mIhon"
   },
   "source": [
    "**Fit 100 networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1oRW72ps9sOsr81CyIUj5LkgaQFt_z4-7"
    },
    "executionInfo": {
     "elapsed": 7051561,
     "status": "ok",
     "timestamp": 1630960967678,
     "user": {
      "displayName": "Facundo Fainstein",
      "photoUrl": "",
      "userId": "02917735191270360821"
     },
     "user_tz": 180
    },
    "id": "lFKIldGuIg55",
    "outputId": "f59406a8-b10e-4ed4-8509-a9d8f1a88238"
   },
   "outputs": [],
   "source": [
    "#Define data \n",
    "X = x_der.reshape(x_der.shape[0], x_der.shape[1]*x_der.shape[2])\n",
    "#Compute velocity of the graphical projection\n",
    "d_frames_test = np.sqrt(np.sum(np.diff(X[300:],axis=0)**2,axis=1))\n",
    "\n",
    "#Number of trainings\n",
    "N=100\n",
    "#Path to save folder\n",
    "path = f'/home/.../'\n",
    "\n",
    "for k in range(N):\n",
    "    \n",
    "    print('iteracion ' + str(k) + ' de '+str(N))\n",
    "    #Create name to save training results\n",
    "    directory= 'it{}'.format(k)\n",
    "    #Path to saving folder, create directory if necessary\n",
    "    model_path = os.path.join(path, directory)\n",
    "    Path(model_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #Train and save\n",
    "    (train_mse,val_mse,layer_output_train,\n",
    "    layer_output_test) = train_save(X,model_path=model_path)\n",
    "  \n",
    "    #Compute velocity in latent space \n",
    "    d_ls_test = np.sqrt( np.diff(layer_output_test[:,0])**2 + \n",
    "                              np.diff(layer_output_test[:, 1])**2 ) \n",
    "\n",
    "    #Plot result\n",
    "    plt.figure(figsize=(15,3))\n",
    "    plt.subplot(1,5,1)\n",
    "    plt.title(directory)\n",
    "    plt.plot(layer_output_train[:,0])\n",
    "    plt.plot(layer_output_train[:,1])\n",
    "    plt.subplot(1,5,2)\n",
    "    plt.plot(layer_output_test[:,0])\n",
    "    plt.plot(layer_output_test[:,1])      \n",
    "    plt.subplot(1,5,3)\n",
    "    plt.plot(layer_output_test[:,0],layer_output_test[:,1],'.')\n",
    "    plt.subplot(1,5,4)\n",
    "    plt.plot(train_mse, label=\"train\")\n",
    "    plt.plot(val_mse, label=\"test\")\n",
    "    plt.ylim([min(val_mse)-min(val_mse)*0.2, val_mse[25]+val_mse[25]*0.2])\n",
    "    plt.subplot(1, 5, 5)\n",
    "    plt.plot(d_frames_test, c='k', label=\"d frames\")\n",
    "    plt.gca().twinx().plot(d_ls_test, alpha=0.7, label=\"d l-space\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1YgTJF2HyeY-E0_KzZHuerP_DNsau8uwr",
     "timestamp": 1630448146369
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
